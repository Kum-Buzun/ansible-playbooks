input {
  # Syslog
  file {
    path => "/var/log/messages"
    type => "syslog"
    sincedb_path => "/var/run/logstash_sincedb"
    stat_interval => 10
  }
  # Nginx access
  file {
    path => "/var/log/nginx/*.access.log"
    type => "nginx_access"
    sincedb_path => "/var/run/logstash_sincedb"
    stat_interval => 10
  }
  # Nginx error
  file {
    path => "/var/log/nginx/*.error.log"
    type => "nginx_error"
    sincedb_path => "/var/run/logstash_sincedb"
    stat_interval => 10
  }
  # Maria DB Slow queries
  file {
    path => "/var/log/mysql/mysql-slow.log"
    type => "mysql-slow"
    sincedb_path => "/var/run/logstash_sincedb"
 
    # Key breaking the log up on the # User@Host line, this will mean
    # sometimes a # Time line from the next entry will be incorrectly
    # included but since that isn't consistently present it can't be
    # keyed off of
    #
    # Due to the way the multiline codec works, previous must be used
    # to collect everything which isn't the User line up. Since
    # queries can be multiline the User line can't be pushed forward
    # as it would only collect the first line of the actual query
    # data.
    #
    # logstash will always be one slow query behind because it needs 
    # the User line to trigger that it is done with the previous entry.
    # A periodic "SELECT SLEEP(1);" where 1 is above the slow query
    # threshold can be used to "flush" these events through at the
    # expense of having spurious log entries (see the drop filter)
    codec => multiline {
      pattern => "^# User@Host:"
      negate => true
      what => previous
    }
  }
}

filter {
  if [type] == "nginx_access" {
    grok { 
      match => { "message" => "%{COMBINEDAPACHELOG}" }
      match => { "path" => "%{GREEDYDATA}/%{GREEDYDATA:app}.access.log" }
      break_on_match => false
    }
  }
  if [type] == "nginx_error" {
    grok { 
      match => { "message" => "(?<timestamp>%{YEAR}/%{MONTHNUM:month}/%{MONTHDAY:day} %{TIME}) \[%{WORD:class}\] %{GREEDYDATA:errmsg}, client: %{IPORHOST:clientip}, server: %{IPORHOST:server}, request: \"%{WORD:verb} %{URIPATHPARAM:request} (?:HTTP/%{NUMBER:httpversion})?|-\", host: \"%{IPORHOST:host} \"" }
      match => { "path" => "%{GREEDYDATA}/%{GREEDYDATA:app}.error.log" }
      break_on_match => false
      add_field => [ "response", "50X" ]
    }
  }
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
      add_field => [ "received_from", "%{host}" ]
    }
    if !("_grokparsefailure" in [tags]) {
      mutate {
        replace => [ "@source_host", "%{syslog_hostname}" ]
        replace => [ "@message", "%{syslog_message}" ]
      }
    }
    mutate {
      remove_field => [ "syslog_hostname", "syslog_message"]
    }
  }
}

output {
  elasticsearch {
    # host here
  }
}
