input {
  # Syslog
  file {
    path => "/var/log/messages"
    type => "syslog"
    sincedb_path => "/var/run/logstash_sincedb"
    stat_interval => 10
  }
  file {
    path => "/var/log/syslog"
    type => "syslog"
    sincedb_path => "/var/run/logstash_sincedb"
    stat_interval => 10
  }
  # Brad (if exists)
  file {
    path => "/var/log/brad/brad.log"
    type => "bradlog"
    sincedb_path => "/var/run/logstash_sincedb"
    stat_interval => 10
  }
  # Nginx access
  file {
    path => "/var/log/nginx/all.access.log"
    type => "nginx_access"
    sincedb_path => "/var/run/logstash_sincedb"
    stat_interval => 10
  }
  # Nginx error
  file {
    path => "/var/log/nginx/*.error.log"
    type => "nginx_error"
    sincedb_path => "/var/run/logstash_sincedb"
    stat_interval => 10
  }
  # Maria DB Slow queries
  file {
    path => "/var/log/mysql/mariadb-slow.log"
    type => "mysql-slow"
    sincedb_path => "/var/run/logstash_sincedb"
 
    # Key breaking the log up on the # User@Host line, this will mean
    # sometimes a # Time line from the next entry will be incorrectly
    # included but since that isn't consistently present it can't be
    # keyed off of
    #
    # Due to the way the multiline codec works, previous must be used
    # to collect everything which isn't the User line up. Since
    # queries can be multiline the User line can't be pushed forward
    # as it would only collect the first line of the actual query
    # data.
    #
    # logstash will always be one slow query behind because it needs 
    # the User line to trigger that it is done with the previous entry.
    # A periodic "SELECT SLEEP(1);" where 1 is above the slow query
    # threshold can be used to "flush" these events through at the
    # expense of having spurious log entries (see the drop filter)
    codec => multiline {
      pattern => "^# User@Host:"
      negate => true
      what => previous
    }
  }
}

filter {
  if [type] == "nginx_access" {
    grok { 
      match => { "message" => "%{COMBINEDAPACHELOG} \"(?<app>[a-zA-Z0-9._-]+)\"" }
    }
  }
  if [type] == "bradlog" {
    grok { 
      match => { "message" => "(?<timestamp>%{YEAR}/%{MONTHNUM:month}/%{MONTHDAY:day} %{TIME}) %{IPORHOST:host} %{WORD:action}\[%{WORD:app}@%{WORD:env}\] : (%{WORD:user}) %{GREEDYDATA:brad_message}" }
    }
  }
  if [type] == "nginx_error" {
    grok { 
      match => { "message" => "(?<timestamp>%{YEAR}/%{MONTHNUM:month}/%{MONTHDAY:day} %{TIME}) \[%{WORD:class}\] %{GREEDYDATA:errmsg}, client: %{IPORHOST:clientip}, server: %{IPORHOST:server}, request: \"%{WORD:verb} %{URIPATHPARAM:request} (?:HTTP/%{NUMBER:httpversion})?|-\", host: \"%{IPORHOST:host}\"" }
      match => { "path" => "%{GREEDYDATA}/%{GREEDYDATA:app}.error.log" }
      break_on_match => false
      add_field => [ "response", "50X" ]
    }
  }
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:timestamp} %{SYSLOGHOST:source_host} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
    }
    syslog_pri { }
  }
}

output {
  elasticsearch {
    # host here
  }
}
